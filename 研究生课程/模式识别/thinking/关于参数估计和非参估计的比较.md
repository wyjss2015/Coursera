#参数估计和非参估计比较
##参数估计
* **比如: **高斯分布
* **优点: **只需存储参数，内存和计算开销小
* **缺点: **一种特定的模型只能拟合特定的分布，不够灵活

##非参估计
* **比如: **kernel方法，k紧邻法
* **优点: **不受数据分布的限制
* **缺点: **需要存储所有训练样本，计算和存储开销大
	
##总结
* 机器学习的目标:寻找灵活性更强的参数化模型